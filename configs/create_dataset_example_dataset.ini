[SETTINGS]
#images are asumed to be in this format
datatype = .tif

#CREATION OF LABELS VIA arcpy
#labels are annotated in a GIS  project 
gdb_file 		= example_dataset/arcgis/example_dataset.gdb
#this can normally be identicall to  'gdb_file'
arcpy_workspace 	= example_dataset/arcgis/example_dataset.gdb
#in order to burn in buildings ontop of the AI-generated data we need acess to a database with building-polygons
arcpy_workspace_buldings 	= example_dataset/arcgis/example_dataset.gdb
#the field that defines what id each polygon belongs to
category_field		= ML_CATEGORY
#if several polygons overlap one of the polygons should have priority depending on the value in this field
priority_field		= ML_PRIORITY
#should we crate a label image also when there is no label data for the area? Normally set to FALSE
includeEmptyFiles	= FALSE
#defines how many m2 we see in each pixel
outputCellSize		= 0.1

#the name of the feature class in wich the label-polygons are drawn
mask_featureclass 	= merged_labels

#the name of the feature class in wich the house polygons are stored
house_featureclass 	= DAGI_M_A_BYGNING

#different persons that works on creating labels save their labels to different feature_classes in order to avoid locking each other out of the deatureclass
#these are merged to 'mask_featureclass'

#Example of situation where several feature classes needs to be merged
#unmerged_feature_classes = example_dataset/arcgis/example_dataset.gdb/labels_John;example_dataset/arcgis/example_dataset.gdb/labels_Paul;example_dataset/arcgis/example_dataset.gdb/labels_George;example_dataset/arcgis/example_dataset.gdb/labels_ringo;example_dataset/arcgis/example_dataset.gdb/example_dataset_labels;
unmerged_feature_classes = example_dataset/arcgis/example_dataset.gdb/example_dataset_labels;


#pixels not covered by any polygon will get this id (typically 0 or 255)
ignore_id = 0
#areas manually labeled as 'unknown' (id 9) should be relabeled to the same id as "ingore_id" (0)
unknown_value2 =9



#when creating the labels we first store the 'raw-labels' 
raw_mask_folder 		= example_dataset/labels/raw_large_label

#The raw labels are then loaded and the pixels without any values are changed to the number defined with 'ignore_id'
mask_folder 		= example_dataset/labels/large_label
splitted_mask_folder 		= example_dataset/labels/splitted_labels

#houses should be saved in this folder
raw_mask_folder_houses 		= example_dataset/houses/raw_large_houses
#The raw labels are then loaded and the pixels without any values are changed to the number defined with 'ignore_id'
mask_folder_houses 		= example_dataset/houses/large_houses

#when the houses are splitted they will be saved in this folder
splitted_mask_folder_houses 		= example_dataset/houses/splitted_houses

#folder where the 'lod-images' should be stored. These images form the basis of our dataset before extra channels are added to them and some of them are removed becaus of lack of label data. We will create one label for each image in this set (if there are any label data for the area)
#image_folder 		= T:/trainingdata/befastelse/befaestelse_dataset_creation_test/data/large_lod_rgb_images

#SPLITTING UP THE DATA AND LABELS INTO PATHCES
#defining how large the pathces should be
tile_size_y = 1000
tile_size_x = 1000

#how many pixels should ther be of overlap between the patches?
overlap= 40

#All differetn kinds of images (lod images, DSM etc etc) are from the beginning located in the same folder
folder_containing_all_image_types = example_dataset/data/original_data

#the different kinds of images (cir == lod_cir  .tif == lod_rgb)
datatypes = ["DSM","DTM","OrtoCIR","OrtoRGB","cir","rgb"]

data_folder = example_dataset/data
splitted_data_parent_folder = example_dataset/data/splitted
images_that_define_areas_to_create_labels_for = example_dataset/data/OrtoRGB
#

#DEFINING TRAIN AND VALIDATION SETS
#used for creating the all.txt train.txt and valid.txt that defines what images we train and validate on. This folder is normally identicall to the one identified by 'splitted_image_folder' 
#path_to_images = T:/trainingdata/befastelse/befaestelse_dataset_creation_test_2/data/splitted_OrtoRGB
all_txt_filename = example_dataset/data/all.txt
valid_txt_filename = example_dataset/data/valid.txt
train_txt_filename = example_dataset/data/train.txt

#when dividing the dataset into train and validation set we select every 5th image for the validation set
#on a larger dataset every 17 or higher might be more suitable
nr_of_images_between_validation_samples = 5
